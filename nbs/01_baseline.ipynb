{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLO('../models/yolov8n-seg.pt', 'segment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo.train(data='./yolo-config.yaml', epochs=5, batch=4)\n",
    "valid_results = yolo.val()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, PIL\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../data/images/clodding_train_005.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLO('../runs/segment/train6/weights/best.pt', 'segment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 544x640 13 ROCKs, 125.3ms\n",
      "Speed: 5.5ms preprocess, 125.3ms inference, 26.1ms postprocess per image at shape (1, 3, 544, 640)\n"
     ]
    }
   ],
   "source": [
    "res = yolo(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(result):\n",
    "    '''get segmentation mask from yolo model'''\n",
    "    def extract_points(mask): \n",
    "        return mask.xy[0].astype(np.int32)[None]\n",
    "    \n",
    "    res = np.zeros(result.orig_shape, dtype=np.uint8)\n",
    "    for mask in result.masks:\n",
    "        res = cv2.fillPoly(res, extract_points(mask), 255)\n",
    "    return res\n",
    "\n",
    "def merge_with_mask(image, mask, p=0.2, gamma=0):\n",
    "    mask_color = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)*np.array([0,1,0], np.uint8)\n",
    "    return cv2.addWeighted(image, 1-p, mask_color, p, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import threading\n",
    "from IPython.display import display, Image\n",
    "from queue import Queue\n",
    "\n",
    "def display_frames(queue):\n",
    "    display_handle = display(None, display_id=True)\n",
    "    while True:\n",
    "        print('q read')\n",
    "        frame = queue.get()\n",
    "        if frame is None:\n",
    "            break\n",
    "        display_handle.update(Image(data=frame.tobytes(), width=500, height=400))\n",
    "\n",
    "def process_and_display(video, func=None):\n",
    "    if func is None: \n",
    "        func = lambda x: x\n",
    "\n",
    "    video = cv2.VideoCapture('../data/clods.mp4')\n",
    "    queue = Queue()\n",
    "\n",
    "    display_thread = threading.Thread(target=display_frames, args=(queue,))\n",
    "    display_thread.start()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            _, frame = video.read()\n",
    "            if frame is None:\n",
    "                break\n",
    "            _, frame = cv2.imencode('.jpeg', func(frame))\n",
    "            print('q write')\n",
    "            queue.put(frame)\n",
    "    except KeyboardInterrupt:\n",
    "        print('Get keyboard interrupt')\n",
    "    finally:\n",
    "        video.release()\n",
    "        queue.put(None)\n",
    "        display_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('../data/clods.mp4')\n",
    "_, frame = video.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_frame(frame): return merge_with_mask(frame, get_mask(yolo(frame)[0]))\n",
    "\n",
    "process_and_display('../data/clods.mp4', segment_frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
